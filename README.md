![Static Badge](https://img.shields.io/badge/Repo_Status%3A-Work_in_Progress-blue?style=flat&logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAAC0AAAAiCAMAAAD8kqB9AAAClFBMVEUAAAD%2F%2F%2F%2FBYzTCysr2WxvyQRLnSibjUy3VZSLbQyvSjHHIjEX5%2F%2F%2F5%2B%2FvIz9D8%2F%2F%2F4WhryWRz3QBHxUR7ySh%2FxbBjsTiHwbxnnTCXVQiz96eTg4N%2Fd3dzL0tH0XDPFzc32SRv0UB%2F3WRr4XRn1SR32VBv1Uhz0TB71URz0QBDySh3%2FYAP4ZxT1YxnwXRz0ZxnvTh7vVR7yPhDxQhfrTB%2FcVCLfRSzUUCfdPCbLciPQOjLu8fHc5OXn5eT85uHj4uHY19bKt6%2F3WBv2Uhv0WS%2F1TSDyWjT0Sx33XBr3Vhv0Vxz3XRr3Xhr1Uhv0Ux30SRv0Whv3Yhn2Xhr0UhzzPg%2F2RBb0Tx7zPg%2FzPg7zUR33YxjyTh%2F7XgL6WQDxTh%2FwVB%2F3Pw%2FzPA3wTh7zYRv1aBntTCDxXhzrTx%2FwSh7oYCDxaxjuTiDmSyHsWR7rPxnoQiXnchrmehr%2B9%2FTs7%2FD%2B7unW2djQ19jm2dbHxcLKuLD3v6%2FJrKL1SRvvelv25ePBxML7aRfg7%2FbS5ezY7PDA1t32VBv2UBz0SR70QxT0QxT0QxT2VRv1VRz3Yhn1Sx34VRvyTB%2F1Sh71Rhj2Uhz2TBj3YRn3Yxn1RBb5ZBfxTB%2F2ZBn7Zgz4Zhj4QhPuWB30ZBrySR3yXhzvSyDvWRv3PxDvTR%2F0WRzyYhvyPQ32aRryahrvViDuYhnxQRPzbRrsRh%2FYXSPuchnrcxjRp5vqbEr5v6%2F0cU3wWDD849vQqqD3pI32n4b2moDfhmznlmTocVD0XjX5Vhrl5ubKtKvirZ%2FPpprTpZbWnI%2F8q3z2lnv4lHn5pXXwn27fhGrfgmjlkF%2F5klzmclPjcFD1bUn0Z0Ptd0H3bDb0VCr0WyT4WRn7YRf4PQvBMCeZAAAAs3RSTlMA%2FQj72VQnHBIPBgX%2B%2Fv78%2BKqajGI0LyolBv7%2B%2Fv79%2FPX09PTu287Cv7%2B1oqCTi394c1pONCIYFRINCv7%2B%2Fv7%2B%2Fv79%2Ffv39fHw7evp4uHS0M%2FMysXFwbq4s7Cwq6SimpGQgX59eHJoYFlRUElHRD8sGRX%2B%2Fv7%2B%2Fv7%2B%2Fv7%2B%2Fv38%2FPv6%2Bvn57u3p4%2BLd19bV0tLNzcrIwsC5trSnp6eioJ%2Bem5uVlZWRkIiDbmlcS0tEOTQjHZlkpy4AAAI7SURBVDjLYqAPyBHU0Y6NjZlvCuZxLp%2BtrR2jI5iOS7nWjX2nT1xQ5ARzuKdc3Xf%2BzDV%2Fdlyq2dt3NvHbqUhAzJ50vKWxzi0Pt1sSttRLM25bAWYbbXd0YDwVgcflEirH%2BHi2dpoBmVyhe%2BWtd7isBTLxGM4MNDyRQZKBdXtlKf%2FJCLzBwua%2BGWh4BzsDE8RoY%2FyhuGQLsz3%2F5USg0Y4yjHvCufCrZlPYLMuztYt9%2Bjk%2BXjs5Y0JRJAQ0nHFbiNthaaDRQD4RhlfdPsvHKyXHSjj%2BhfYz2xbVVtsw7tbkIqxaAmg4b3kFwmjChh%2BSgRhNGIi57iyTKS45YIRDHiAONMMvyjvw70Iz2hzOMs3kQDX8qI3UARRXc2duQJLXW4MsN%2FdS864QJiQBUb1cZHnTeQvFETwTxSNXkFxdoCdoguZ2wwDdjXDOguvqcKMLkwOEOTG8mh%2FpoysOM7xGBMrapM8SnIM1aDL8PGat4waxJFPZIe7V9fZNlcQRklYiagKB%2BqLcEJ74yqlKqklmeGLGyjjSU3laimiB%2BCrAoryVwkTMgYGHUzHIUjMDr1sNPso3BeLZcKpjMmfisEwTzErRiQpUVurXmNgm0Dtjjn7WsuRCDqAMWvj1%2BAWxsHgcdPJUnRwnst6CwVIsQ1ij28vpoAALS5Ca6mIU1aujVaINklp9s%2FMtkEQ52fKCneMN4tzDDNGcsmiCsIZzGoYLcxXVhNW1mNCFLZb6q2MrILO1%2BmZKYPMorlBlIBcAACpxj1lvNSqgAAAAAElFTkSuQmCC&labelColor=%23232D4B&color=%23E57200)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

# **Introduction**

## **Project Goal**:
Data Scientists and analysts have developed several metrics for determining a player's value to their team's success. Prominent examples include Value Over Replacement Player (VORP), Box Plus/Minus (BPM), and FiveThirtyEight's Robust Algorithm (using) Player Tracking (and) On/Off Ratings (RAPTOR)​. We aim to develop a multivariate index that weighs these parameters based on how well they predict MVP rankings, then test it on unseen data for the most recent five seasons to see if our "MVP index" correctly predicts the MVP rankings.​ We will experiment with the index formula and compare it to other methods developed by reputable analyst sources.

## **Data**:

...

## **Experimental Design**:

**Note on compute resources**:

We use Rivanna – the University of Virginia’s High-Performance Computing (HPC) system – with the following hardware details:

* **System**: Linux
* **Node Name**: udc-an34-1
* **Release**: 4.18.0-425.10.1.el8_7.x86_64
* **Version**: #1 SMP Thu Jan 12 16:32:13 UTC 2023
* **Machine**: x86_64
* **CPU Cores**: 28
* **RAM**: 36GB
* **CPU Vendor**: AuthenticAMD
* **CPU Model**: AMD EPYC 7742 64-Core Processor

### Feature Selection Process:

We perform robust feature selection to reduce model and index complexity. The main code we use for feature selection can be found in `preptrain.py`. This Python module file includes a function, `preprocess_and_train`, which we employ in `FeatureSelection.ipynb`. We wrote the function to perform the following:

* Impute missing values with the median value for numeric features, scale the features using standardization (subtracting the mean and dividing by the standard deviation), and apply one-hot encoding while ignoring unknown categories for categorical features.

* Apply the preprocessing separately to the training and testing datasets and extracts the feature names from the ColumnTransformer object, removing any prefixes.

* Train and test eight different modeling techniques on the preprocessed data and extract the feature importance scores of the top ten predictors for:

  - Random Forest (RF)
  - Decision Tree (DTree)
  - Principal Component Analysis (PCA)
  - Gradient Boosting (GBM)
  - Support Vector (SVR)
  - Extra Trees (XTrees)
  - AdaBoost (Ada)
  - Extreme Gradient Boosting (XGB)

For hyperparameter tuning, we define a reasonably extensive parameter grid for each method and use Bayesian optimization with five-fold cross-validation to sample parameter settings from the specified distributions.

In this the `FeatureSelection.ipynb` notebook, we run the `preprocess_and_train` and use the `print_dict_imps` function from `print_imps.py` to print out tables of the feature importances for each method, which are stored in a Python dictionary via the `preprocess_and_train` function.

We then use the `avg_imp` function from `print_imps.py` to display the average feature importance across the eight methods. The results for the top 10 features included several features related to points (scoring) that are highly correlated, including FT (free throws), 2P (two-pointers), FG (field goals), FGA (field goal attempts), FTA (free throw attempts) and PTS (points):

![](images/corr_matrix1.png)

We chose to drop all of these except PTS because PTS effectively captures the others. The resulting top 10 features are:

- OWS = Offensive Win Shares (see <a href="https://www.basketball-reference.com/about/ws.html">NBA Win Shares</a> for more information on how this is calculated)
- MP = Minutes Played
- PTS = Points
- WS = Win Shares (see <a href="https://www.basketball-reference.com/about/ws.html">NBA Win Shares</a> for information about how this feature is calculated)
- VORP = Value Over Replacement Player
- PER = Player Efficiency Rating (see <a href="https://www.basketball-reference.com/about/per.html">Calculating PER</a> for the formula)
- TOV = Turnovers
- AST = Assists
- TS% = True Shooting Percentage
- Rk_Year = Team league ranking

There are still some highly correlated features, but we proceed with these 10 and use them for modeling in `Models.ipynb`.

In the `Models.ipynb` notebook, we train and test only the ensemble and tree-based methods, as these are best suited for the next task: finding the best model we can and using the feature importance scores to inform our index design. So, we train, test, and compare six models, including:

* Random Forest (RF)
* Decision Tree (DTree)
* Gradient Boosting (GBM)
* Extra Trees (XTrees)
* AdaBoost (Ada)
* Extreme Gradient Boosting (XGB)

The image below displays the feature importance score from each model.

![](images/features_table.png)

The table shows that, on average, Win Shares (WS) and then Value Over Replacement Play (VORP) are the most important features. However, we see a wide variety of importance scores for each feature across the various models.

![](images/model_comp.png)

The combined split-bar plot above highlights the best-performing model (the Extra-trees regressor), which barely outperforms the Extreme GradientBoosting Regressor (XGBoost). We save the best ExtraTrees model from Models.ipynb and import it into Test.ipynb, where we test it against the 2018–22 seasons.

TO BE CONTINUED AFTER TESTING ...

## **Manifest**:

<details>
<summary><img src="images/ipynb.png" align="left" width="40" height="40" /> Jupyter Notebooks</summary>
  
- ### FeatureSelection.ipynb:

  Feature Selection notebook where we use the `preprocess_and_train` function from `preptrain.py` and ensemble the methods to generate the best 10 features.
  
- ### DataCleaning_EDA.ipynb:
  
  Exploratory notebook where the data is cleaned; includes some basic EDA.

- ### Models.ipynb:

  Modeling notebook where we use the selected features (from `df_selected.csv`) to train and evaluate a range of models and extract their feature importance. These results will inform how we weight features in the index.

- ### Test.ipynb:

  This notebook contains the code where we test our best model (from `Models.ipynb`) against the last five seasons. We include some visualizations showing the model prediction versus the actual values.

</details>
<br>
<details>
<summary><img src="images/csv.png" align="left" width="40" height="40" /> Data Files</summary>
  
- ### df_clean.csv:
  
  Main .csv file used for training and validation.

- ### df_last.csv:
  
  Testing .csv file for examining model performance on last 5 seasons (2018-22).

- ### df_selected.csv:

  Selected features .csv containing the subset of predictor variables.

- ### mvp_data.csv:
  Initial NBA mvp data set. Reduced in `DataCleaning_EDA.ipynb` to only include essential rows and columns of study.
</details>
<br>
<details>
<summary><img src="images/py.png" align="left" width="40" height="40" /> Python Module Files (helper functions, classes)</summary>
  
- ### pltcorrheatmap.py:
  
  Custom function to generate correlation heat maps to help determine multicollnearity as we examine feature importance.

- ### print_imps.py:

  Custom function to print model feature importance scores for the selected features.

- ### preptrain.py:
  
  Custom function/pipeline for preprocessing and feature selection, described below:

  - Defining Numeric Columns (Excluding "Pos"):

    This step identifies the numeric columns in the input DataFrame `df`, excluding the "Pos" column for player position.

  - Splitting Data into Training and Testing Sets:

    Splits the input data into training and testing sets using the `train_test_split` function from `scikit-learn`.

  - Defining Preprocessing Steps:

    We impute missing values with the median value for numeric features and then scale the features using standardization (subtracting the mean and dividing by the standard deviation). We apply one-hot encoding while ignoring unknown categories for categorical features (specifically "Pos").

  - Preprocessing Training and Testing Data:

    Applies the preprocessing separately to the training and testing datasets using the `fit_transform` and `transform` methods of the `ColumnTransformer`.

  - Extracting Feature Names:

    This step extracts the feature names from the `ColumnTransformer` object, removing any prefixes such as "num__" or "cat__."

  - Filter Method - SelectKBest:

    Uses SelectKBest with ANOVA F-value to select the top 10 features based on their scores. These scores represent the strength of the relationship between each feature and the target variable.

  - Wrapper Method 1 - Random Forest Feature Importance:

    Trains a Random Forest Regressor on the preprocessed training data to determine feature importance and selects the top 10 features with the highest feature importance scores.

  - Embedded Method - L1-based feature selection using Lasso:

    Uses LassoCV (Lasso Cross-validation) to perform L1-based feature selection, iteratively fitting Lasso models with different regularization strengths (alphas) and selecting features based on non-zero coefficients.

  - Performs Principal Component Analysis (PCA):

    Performs PCA to reduce the dimensionality of the data and select the top 10 principal components as features.

  - Stability Selection with Lasso:

    Uses Stability Selection with Lasso to select features. We apply LassoCV within SelectFromModel to select features based on stability across multiple Lasso models.

  - Recursive Feature Elimination with Cross-Validation (RFECV):

    Applies RFECV, a wrapper method that recursively selects features by recursively training the model and selecting the best-performing subset of features through cross-validation.

  - Wrapper Method 2 - Gradient Boosting Machine Feature Importance

    Trains a Gradient Boosting Machine model on the preprocessed training data to determine feature importance and selects the top 10 features with the highest feature importance scores.

  - Embedded Method 2 - Support Vector Regressor

    Uses Support Vector Regressor (SVR) within SelectFromModel to perform embedded feature selection. Features are selected based on the coefficients obtained from the SVR model.

  - Preparing Final Data for Training:

    Extracts the selected features from the preprocessed training and testing data and prepares the final datasets (X_train, X_test, y_train, y_test) for model training and evaluation.

  - Returning Results:

    The function returns various components: the selected features from each method (features_filter, features_wrapper, features_embedded), the names of the selected features (feature_names), and the preprocessed training and testing data along with their corresponding labels.
</details>
